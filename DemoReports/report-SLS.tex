% !TEX root = demoReport.tex
\section*{Problem 2: Stochastic Local Search (SLS)}

%\todo{
%  %% delete this paragraph, including its footnote:
%  The \emph{investment design problem} is about finding a matrix of
%  $v$~rows and $b$~columns of~$0$-$1$ integer values, such that each
%  row sums up to~$r$, with $v \geq 2$ and $b \geq r \geq 1$, and the
%  largest dot product between all pairs of rows is minimised.
%  % 
%  Equivalently, one has to find~$v$ subsets of size~$r$ within a given
%  set of $b$~elements, such that the largest intersection of any two
%  of the $v$~sets has minimal size.
%  % 
%  An instance of the problem is parametrised by a
%  triple~$\Tuple{v,b,r}$.\footnote{\todo{Your report need not contain
%      an explanation of the problem to be solved: you can assume the
%      reader has read th e problem statement in the assignment
%      instructions.  We just repeat it here for self-sufficiency of
%      this document.}}
%  
%  %% delete this paragraph:
%  This is an abstract description of a problem that appears in
%  finance: see Figure~\ref{fig:wallStreet}.  In a typical investment
%  design in finance, we have $4 \leq v \leq 25$ and
%  $250 \leq b \leq 500$, with $r \approx 100$.
%
%  %% delete this figure:
%  \begin{figure}[b]  % make it float to the bottom of a page
%    \centering
%    \includegraphics[height=5cm]{wallStreet}
%    \caption{\todo{Wall Street (\copyright\ www.forbes.com, 2014)}}
%    \label{fig:wallStreet}
%  \end{figure}
%  
%  %% delete this paragraph, if you want:
  A lower bound on the number~$\lambda$ of shared elements of any
  pair among $v$~subsets of size~$r$ drawn from a given set of
  $b$~elements is given in~\cite{ASTRA:AOC}:
  \begin{equation}\label{eq:lb}
  \text{lb}(\lambda) = 
    \Ceiling{
      \frac{\Ceiling{\frac{rv}{b}}^{2} ((rv) \bmod b)  +
        \Floor{\frac{rv}{b}}^{2} (b - ((rv) \bmod b)) - rv}
      {v(v-1)}
    }
  \end{equation}
%  
%}

\paragraph{Task~a: SLS Algorithm.}
\begin{enumerate}
\item Representation. 
The current state of the local search is given by a $v \times b$ matrix, where each row $v$ is a binary array of length $b$ where there are always $r$ elements that are $1$. 
%\todo{Describe how to represent the problem:
%  what are the variables, their meanings, their constraints, and the
%  objective function?}

  
\item Initial Assignment. It is made by randomly generating $v$ binary arrays where $r$ ones are randomly positioned. %\todo{Describe an algorithm for generating
%  (fast) a randomised initial assignment.}
\item Move. Each move we make is a switch in one row, making a permutation of a zero element with a one element.
%. With a probability of $\alpha$ we instead make a random move, and with a probability $\beta$ we make a random restart. 
%\todo{Describe one or more moves that go from an
%  assignment to a neighbouring assignment by changing the values of
%  a few variables.}
\item Constraints. Each row must have exactly $r$ elements which are one, which is a built in constrain which is never violated, because we only make swaps in the moves and each row gets initialised this way. 
%\todo{Describe for each constraint how its
%  satisfaction is either algorithmically checkable efficiently or
%  guaranteed to be preserved by the previous two design choices.}
\item Neighbourhood. As for each of the $v$ rows, we create one possible move, there is a total of $v$ moves in the neighbourhood. The search space in connected, as each permutation of $r$ from $b$ elements can be found from a finite sequence of permutations and switches. As we can reach every feasible configuration for $1$ row, we can also reach every feasible configuration of the matrix, but there will most likely be moves that increase cost between any given configuration and an optimal solution. The size of the neighbourhood is $v\cdot r \cdot (b-r)$. 
%\todo{Describe a neighbourhood based on the
%  described moves.
%  % 
%  Derive a formula for computing the size of the neighbourhood in
%  terms of the problem parameters.  
%  % 
%  Discuss whether the neighbourhood makes the search space connected,
%  in the sense that every feasible assignment (that is, every
%  assignment satisfying all the constraints, whether optimal or not)
%  is reachable from every initial assignment (you only need to sketch
%  a proof if the search space is connected, and give a counterexample
%  otherwise).}
\item Cost Function. Let $v_i$ and $v_j$ be the $i$-th and $j$-th row of a configuration. Then our cost function is given by: 
\begin{equation*}
 \mathsf{cost} = \max_{i \neq j}\: v_i \cdot v_j 
\end{equation*}

%\todo{Describe a cost function, whose value is
%  to be minimised during search.}
\item Probing.  
%\todo{
% Describe how a neighbouring assignment, as
%  reachable by a move, can be probed efficiently:
We calculate the dot product of the row selected for swap, swap the elements we want to probe, and we get the largest product as output. This number is compared with the cost of the configuration before the swap, and should the cost decrease by 1 we have an improvement, If the cost increases, it means we are increasing the row cost, increasing the total cost by $+1$, or $0$ implying no improvement. 
  % 
%  describe how the cost function can be evaluated efficiently and
%  incrementally, and describe the data structures used to do so.
As the rows are represented in arrays, we can evaluate the cost difference from one element of the neighbourhood, we only need to evaluate the dot product of the new row and all the other rows, so we have a complexity of $O(v \cdot b)$
  % 
%  Give, without proof, the time complexity of probing; ideally, it is
%  (sub-)linear in the problem parameters.
%  }
\item Heuristic. We make sure, that when in a given state, we do not probe the same row twice, so that the same neighbour is not probed twice. The entire neighbourhood does is not explored exhaustively and if found the first move that decreases the cost is selected. Once we have probed each row, we know, that the neighbourhood is exhausted, and can make a random move instead, and add the current state in our tabu list. We decided to do it this way, because if we calculate the cost of each neighbour, it would drastically increase the run time. 
%\todo{Describe a heuristic for exploring (via
%    probing) the neighbourhood and selecting a neighbouring assignment
%    to commit to.
%  % 
%  Decide if the neighbourhood is to be explored exhaustively and, if
%  so, how you determine when it was exhausted.
%  % 
%  Explain how to ensure that the same neighbour is not probed twice
%  during a given exploration.}
\item Optimality. As the Equation \ref{eq:lb} gives a lower bound for the maximal cost (except of the input of $\Tuple{10, 8, 3}$, we have found an optimal solution, if we reached the lower bound given by Equation \ref{eq:lb}, and can stop the algorithm. If the number of restarts set in the parameter $\beta$ is reached, we also stop and return the best found configuration up until this point. 
%\todo{Describe how you use a bound on the objective
%  value in order to terminate sometimes the search with proven
%  optimality, as part of the heuristic.}
\item Meta-Heuristic. All moves made before arriving at the suboptimal local minima, will be commited and added to the tabu list for alpha iterations. This prevents the same moves from being made to escape from the local minima and hopefully enter a different neighbourhood.
  
%\todo{Describe a meta-heuristic based on either
%  tabu search (strongly recommended for the investment design
%  problem) or simulated annealing.
%  % 
%  In case of tabu search: explain how the tabu list is represented;
%  choose (a formula for) its size; explain how fine-grained or
%  coarse-grained its content is, conceptually; and describe how it can
%  be looked up and maintained efficiently; note that the tabu list is
%  not necessarily an actual list, but rather a concept; make sure that
%  worsening moves are sometimes made.
%  % 
%  In case of simulated annealing: explain how you chose the cooling
%  function, cooling rate, and initial temperature.}
\item Random Restarts. We can make random restarts when we the probing does not yield a better result. The number of restarts is given by the parameter $\beta$, with the tabu list we will no reach same local minimum again. 
%\todo{Describe how to detect or guess that a
%  random restart should be made, as part of the meta-heuristic.}
%\item Optional Tweaks.  \todo{Describe improvements such as aspiration,
%    diversification, or other ideas that you use to improve your SLS
%    algorithm.}
\end{enumerate}
%In summary, the local-search parameters (not the problem
%parameters~$v$,~$b$,~$r$) are~\todo{$\alpha$ and~$\beta$.}

\paragraph{Task~b: Implementation.}
We chose the high-performance programming language C++, for
which a compiler is available on the Linux
computers of the IT department.  All source code is \todo{uploaded}
with this report.  The compilation and running instructions are
to have all the \textsf{.cpp} files, \textsf{.h} files, \textsf{.cc} file and the makefile in a folder with the terminal in the folder, enter the commands:
\begin{center}
\textsf{make}
\end{center}
and run:
\begin{center}
\textsf{./InvDes {v} {b} {r} }
\end{center}
to run the executable generated on the input parameters of choice $v$,  $b$,  $r$
\begin{center}
\textsf{./InvDes}
\end{center}
to run the executable on the pre-input based on the java skeleton code provided. 

%An executable called \texttt{InvDes} reads the problem
%parameters~$v$,~$b$,~$r$ as command-line arguments and writes to
%standard output a line with the space-separated values
%of~$v$,~$b$,~$r$, the lower bound~$\text{lb}(\lambda)$ on~$\lambda$,
%and the achieved~$\lambda$, 
The executable writes to the standard output a line  followed by one line per row of the time of a run as well as the cost. If the argument $p$ is written before the parameter $v$, $b$ and $r$, then a space separated matrix representing the solution is also printed. 
%a~$v \times b$ matrix representing the solution, the~$0$-$1$ cell
%values being space-separated.

%Our solution is not complete, and we are aware, that this will lead to point deduction. 
% We validated the correctness of our implementation by \todo{checking
%  its outputs on many instances via the provided polynomial-time
%  solution checker}.

\paragraph{Task~c: Experiments.}
%% Note the non-breaking spaces, typeset via ~, between numbers and
%% their units:
All experiments were run under the the \textit{gullviva.it.uu.se} server from the IT department, with Ubuntu 22.04 x86\_64 architecture. 

We attempted to have $\alpha$ be the number of iterations a move will be in the taboo list for, and $\beta$ be the number of restarts from the original starting board to allow the search to escape the local minima, however, changing the parameters led to increased run time but with little to no improvement in performance. We suspect certain helper functions to be bugged that is causing our taboo search to not function as intended and hence its ability to arrive at the optimal solutions is low, where they only remain in the local minima regardless of the alpha beta parameters, hence, we chose to reduce these values to reduce run time.
%
\newcommand{\TimeoutSLS}{\todo{300.0}}  % timeout, in CPU seconds; MIN 300.0
\newcommand{\RunsSLS}{\todo{5}}         % independent runs per instance; MIN 5
%
%The \todo{median} runtime (in seconds), \todo{median} number of steps,
%and \todo{median} achieved~$\lambda$ over~$\RunsSLS$ independent runs
%for each of the $21$~instances of the assignment instructions are
%given in Table~\ref{tab:res:sls}, for \todo{two} configurations
%%% remember: AT LEAST TWO, except for solo teams!
%of values for the local-search parameters~\todo{$\alpha$ and~$\beta$}.
%The timeout was~$\TimeoutSLS$~CPU seconds per run.%
%
%% Delete this footnote:
%\footnote{\todo{Hint: In order to save a lot of time, it is very
%    important that you write a script that conducts the experiments
%    for you and directly generates a result table (see the \LaTeX\
%    source code of Table~\ref{tab:res:sls} for how to do that), which
%    is then automatically imported, rather than manually copied, into
%    your report: each time you change the code, it suffices to re-run
%    that script and re-compile your report, without any tedious
%    copying!  The sharing of scripts is allowed and even encouraged.}}

\begin{table}[t]  % make it float to the top of a page
  \centering
  \begin{tabular}{rrrrrrrrrrr}  % right alignment --> decimal point alignment
    & & &
    & \multicolumn{3}{c}{\todo{$\Tuple{\alpha,\beta}=\Tuple{2,5}$}}
    & \multicolumn{3}{c}{\todo{$\Tuple{\alpha,\beta}=\Tuple{10,20}$}} \\
    \cmidrule(r){5-7} \cmidrule(r){8-10}
    $v$ & $b$ & $r$ & $\text{lb}(\lambda)$
        & time & steps & $\lambda$
        & time & steps & $\lambda$ & exact \\
    \midrule
    \input{results-SLS.tex} %% let your experiment script write directly
                            %% into this file, making sure every number
                            %% in a column has the _same_ number of decimals
  \end{tabular}
  \caption{Investment design: median runtime (in seconds), median
    number of steps, and median achieved~$\lambda$, for \todo{two}
    configurations
    %% remember: AT LEAST TWO, except for solo teams!
    of values for the local-search parameters~\todo{$\alpha$
      and~$\beta$}, over~$\RunsSLS$~independent runs per instance,
    with a timeout of $\TimeoutSLS$~CPU seconds per run.
    %
    The right-most column gives the number of candidate solutions the
    outlined exact algorithm has to examine per second in order
    to match the runtime performance of the seemingly best
    configuration of values for the local-search parameters, namely
    \todo{$\Tuple{\alpha,\beta}=\Tuple{2,5}$}, if the instance
    was solved to proven optimality, and `n/a' for `non-applicable'
    otherwise.
  }\label{tab:res:sls}
\end{table}

%We observe that \todo{\filler}, because \todo{\filler}.

\paragraph{Task~d: Exact Algorithm.}
An exact algorithm could work as follows: It could perform brute force search, trying out all possible non-equivalent configurations. Two configurations are equivalent, if a permutations of the rows leads to both configurations to be the same. This would lower the size of the search space. 
%\todo{discuss its features
%  (for instance, does it perform brute-force search?).}
%
For one row, the search space is given by $\binom{b}{r}$. As we have a total of $b$ rows, there are in total $\binom{b}{r}^v$ possibilities. As the permutation of $v$ elements yield a group of size $v!$, the number of equivalent classes is $b!$. Hence, the total search space is of size 
$$ \frac{\binom{b}{r}^{v}}{v!}$$
 

The number of candidate solutions this exact algorithm has to examine
per second in order to match the runtime performance of the seemingly
best configuration of values for the local-search parameters,
according to Task~c, of our stochastic local search algorithm is given
in the right-most column of Table~\ref{tab:res:sls}, for each instance
solved to proven optimality.
%
%We think that \todo{\filler}, because \todo{\filler}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "demoReport"
%%% End:
